{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c9f46",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59512665",
   "metadata": {
    "title": "[mardown] Part 1: Regression with synthetic data"
   },
   "source": [
    "# Part 1: Regression with l2 penalty and Akaike criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc65fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_dataset(n, p, k, noise):\n",
    "    \"\"\"Q0.\n",
    "\n",
    "    Build the following matrices with Gaussian entries (meaning that every entry is sampled\n",
    "    from a standardized Gaussian distribution)\n",
    "    - X of shape (n, p)\n",
    "    - W of shape (p, k)\n",
    "    - N of shape (n, k)\n",
    "    Then form\n",
    "    - Y = XW + noise * N\n",
    "    and return W, X, Y\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def f(Y, W, X, l):\n",
    "    \"\"\"Q1.\n",
    "\n",
    "    Gives the value of the function\n",
    "    f(Y, W, X, l) = 1/2 ||XW - Y||^2 + l/2 ||W||^2\n",
    "    where || || is the frobenius norm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array of shape (n, p)\n",
    "        Design matrix\n",
    "    Y : array of shape (n, k)\n",
    "    W : array of shape (p, k)\n",
    "        Matrix of parameters\n",
    "    l : float\n",
    "        hyper-parameter\n",
    "\n",
    "    Return\n",
    "    --------\n",
    "    value : float\n",
    "        Value of f(Y, W, W, l)\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def solver(X, Y, l=1):\n",
    "    \"\"\"Q2.\n",
    "\n",
    "    Solves\n",
    "    min_W 1/2||XW - Y||^2 + l/2 ||W||^2\n",
    "    where || || is the frobenius norm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array of shape (n, p)\n",
    "        Design matrix\n",
    "    Y : array of shape (n, k)\n",
    "        Target\n",
    "    l : float\n",
    "        hyper-parameter\n",
    "\n",
    "    Return\n",
    "    --------\n",
    "    W: array of shape (p, k)\n",
    "    W is such that\n",
    "    1/2 ||XW - Y||^2 + l/2 ||W||^2 is minimized\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def test_solver():\n",
    "    n = 128\n",
    "    p = 3\n",
    "    k = 2\n",
    "    W, X, Y = generate_dataset(n, p, k, 0)\n",
    "    l = 1\n",
    "    W_star = solver(X, Y, l)\n",
    "    for _ in range(100):\n",
    "        R = np.random.randn(p, k)\n",
    "        assert f(Y, W_star + R, X, l) > f(Y, W_star, X, l)\n",
    "\n",
    "\n",
    "test_solver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5432385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validated_score(X, Y, l):\n",
    "    \"\"\"Q3.\n",
    "\n",
    "    Compute the cross validated score of the solver\n",
    "\n",
    "    Divide the samples into 5 groups of equal size\n",
    "    Leave out a group\n",
    "    Take the samples corresponding to the groups that are not left out\n",
    "    yielding arrays X_train of\n",
    "    shape (n * 4/5, p) and Y_train of shape (n * 4/5, k)\n",
    "    The remaining samples constitue X_test and Y_test.\n",
    "    Then, apply the solver on X_train Y_train to get W_train\n",
    "    and record\n",
    "    the error of ||Y_test - X_test W_train ||^2\n",
    "\n",
    "    Do this 5 times each time leaving a different group out\n",
    "    and return the mean error.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d42654d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def plot_hyperparameter_curve(X, Y):\n",
    "    \"\"\"Q4.\n",
    "    Plot cross_validated_score  in function of l\n",
    "    with l in a grid of 100 points between 0 and 2\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "W, X, Y = generate_dataset(100, 20, 5, 1)\n",
    "plot_hyperparameter_curve(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bb7121",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def akaike(Y, X, l, noise):\n",
    "    \"\"\"Q5.\n",
    "\n",
    "    Compute the Akaike criterion for\n",
    "    Y = X argmin_W f(Y, W, X, l)\n",
    "    Recall that for the estimator A Y\n",
    "    The akaike criterion is\n",
    "    ||AY - Y ||^2 + 2 noise^2 tr(A) - noise^2 n\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array of shape (n, p)\n",
    "        Design matrix\n",
    "    Y : array of shape (n, k)\n",
    "    l : float\n",
    "        hyper-parameter\n",
    "    noise : float\n",
    "        noise parameter\n",
    "\n",
    "    Return\n",
    "    -------\n",
    "        akaike: float\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f4f915",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def optimal_akaike(Y, X, noise):\n",
    "    \"\"\"Q6.\n",
    "\n",
    "    Compute the optimal parameter $l$ according to the Akaike estimator\n",
    "    with l in a grid of 100 points between 0 and 2\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array of shape (n, p)\n",
    "        Design matrix\n",
    "    Y : array of shape (n, k)\n",
    "\n",
    "    Return\n",
    "    --------\n",
    "    l : float\n",
    "        hyper-parameter\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def test_akaike(Y, X, noise):\n",
    "    \"\"\"Q7.\n",
    "\n",
    "    Compute the cross validated accuracy given by the akaike criterion\n",
    "\n",
    "\n",
    "    Divide the samples into 5 groups of equal size\n",
    "    Leave out a group\n",
    "    Take the samples corresponding to the groups that are not left out\n",
    "    yielding arrays X_train of\n",
    "    shape (n * 4/5, p) and Y_train of shape (n * 4/5, k)\n",
    "    The remaining samples constitue X_test and Y_test.\n",
    "    Then, apply the solver on X_train and Y_train with l chosen\n",
    "    according to the akaike criterion\n",
    "    and record the error of ||Y_test - X_test W_train ||^2\n",
    "\n",
    "    Do this 5 times each time leaving a different group out\n",
    "    and return the mean error.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "W, X, Y = generate_dataset(100, 20, 5, 1)\n",
    "plot_hyperparameter_curve(X, Y)\n",
    "print(\"Akaike cross validated score:\", test_akaike(Y, X, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18021f4",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# PART 2: FMRI\n",
    "# What is fMRI ?\n",
    "\n",
    "Functional magnetic resonance imaging (fMRI) is based on the fact that when local neural activity increases, increases in metabolism and blood flow lead to fluctuations of the relative concentrations of oxyhaemoglobin (the red cells in the blood that carry oxygen) and deoxyhaemoglobin (the same red cells after they have delivered the oxygen). Oxyhaemoglobin and deoxyhaemoglobin have different magnetic properties (diamagnetic and paramagnetic, respectively), and they affect the local magnetic field in different ways. The signal picked up by the MRI scanner is sensitive to these modifications of the local magnetic field. To record cerebral activity during functional sessions, the scanner is tuned to detect this “Blood Oxygen Level Dependent” (BOLD) signal.\n",
    "\n",
    "Brain activity is measured in sessions that span several minutes, during which the participant performs some cognitive task and the scanner acquires brain images, typically every 2 or 3 seconds (the time between two successive image acquisition is called the Repetition time, or TR).\n",
    "\n",
    "A cerebral MR image provides a 3D image of the brain that can be decomposed into voxels (the equivalent of pixels, but in 3 dimensions). The series of images acquired during a functional session provides, in each voxel, a time series of positive real number representing the MRI signal, sampled at the TR.\n",
    "\n",
    " One way to analyze times series consists in comparing them to a model built from our knowledge of the events that occurred during the functional session. Events can correspond to actions of the participant (e.g. button presses), presentations of sensory stimui (e.g. sound, images), or hypothesized internal processes (e.g. memorization of a stimulus), …"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e440590",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare data and analysis parameters\n",
    "# -------------------------------------\n",
    "# Prepare the timing parameters.\n",
    "t_r = 2.4\n",
    "slice_time_ref = 0.5\n",
    "# Prepare the volume-based fMRI data\n",
    "from nilearn.datasets import fetch_localizer_first_level\n",
    "\n",
    "data = fetch_localizer_first_level()\n",
    "fmri_img = data.epi_img\n",
    "\n",
    "# Prepare the experimental paradigm.\n",
    "events_file = data.events\n",
    "import pandas as pd\n",
    "\n",
    "events = pd.read_table(events_file)\n",
    "\n",
    "# Project the fMRI image to the surface\n",
    "# -------------------------------------\n",
    "#\n",
    "# For this we need to get a mesh representing the geometry of the surface. We\n",
    "# could use an individual mesh, but we first resort to a standard mesh, the\n",
    "# so-called fsaverage5 template from the FreeSurfer software.\n",
    "\n",
    "import nilearn\n",
    "\n",
    "fsaverage = nilearn.datasets.fetch_surf_fsaverage()\n",
    "\n",
    "# The projection function simply takes the fMRI data and the mesh.\n",
    "# Note that those correspond spatially, are they are both in MNI space.\n",
    "from nilearn import surface\n",
    "\n",
    "texture = surface.vol_to_surf(fmri_img, fsaverage.pial_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273206dc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# We will perform first level analysis\n",
    "# This involves computing the design matrix and fitting the model.\n",
    "# We start by specifying the timing of fMRI frames.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "n_scans = texture.shape[1]\n",
    "frame_times = t_r * (np.arange(n_scans) + 0.5)\n",
    "\n",
    "###############################################################################\n",
    "# Create the design matrix.\n",
    "#\n",
    "# We specify an hrf model containing the Glover model and its time derivative\n",
    "# The drift model is implicitly a cosine basis with a period cutoff at 128s.\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "\n",
    "design_matrix = make_first_level_design_matrix(\n",
    "    frame_times, events=events, hrf_model=\"glover\"\n",
    ")\n",
    "\n",
    "from nilearn import plotting\n",
    "\n",
    "plotting.plot_design_matrix(design_matrix)\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2854b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The General linear model does a regression like operation\n",
    "#\n",
    "\n",
    "from nilearn.glm.first_level import run_glm\n",
    "\n",
    "labels, estimates = run_glm(texture.T, design_matrix.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3179ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Estimate contrasts\n",
    "# ------------------\n",
    "# Specify the contrasts.\n",
    "#\n",
    "# For practical purpose, we first generate an identity matrix whose size is\n",
    "# the number of columns of the design matrix.\n",
    "contrast_matrix = np.eye(design_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce8754",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###############################################################################\n",
    "# At first, we create basic contrasts.\n",
    "basic_contrasts = dict(\n",
    "    [(column, contrast_matrix[i]) for i, column in enumerate(design_matrix.columns)]\n",
    ")\n",
    "\n",
    "###############################################################################\n",
    "# Next, we add some intermediate contrasts and\n",
    "# one contrast adding all conditions with some auditory parts.\n",
    "basic_contrasts[\"audio\"] = (\n",
    "    basic_contrasts[\"audio_left_hand_button_press\"]\n",
    "    + basic_contrasts[\"audio_right_hand_button_press\"]\n",
    "    + basic_contrasts[\"audio_computation\"]\n",
    "    + basic_contrasts[\"sentence_listening\"]\n",
    ")\n",
    "\n",
    "# one contrast adding all conditions involving instructions reading\n",
    "basic_contrasts[\"visual\"] = (\n",
    "    basic_contrasts[\"visual_left_hand_button_press\"]\n",
    "    + basic_contrasts[\"visual_right_hand_button_press\"]\n",
    "    + basic_contrasts[\"visual_computation\"]\n",
    "    + basic_contrasts[\"sentence_reading\"]\n",
    ")\n",
    "\n",
    "# one contrast adding all conditions involving computation\n",
    "basic_contrasts[\"computation\"] = (\n",
    "    basic_contrasts[\"visual_computation\"] + basic_contrasts[\"audio_computation\"]\n",
    ")\n",
    "\n",
    "# one contrast adding all conditions involving sentences\n",
    "basic_contrasts[\"sentences\"] = (\n",
    "    basic_contrasts[\"sentence_listening\"] + basic_contrasts[\"sentence_reading\"]\n",
    ")\n",
    "\n",
    "###############################################################################\n",
    "# Finally, we create a more relevant contrast\n",
    "#\n",
    "# * 'audio - visual': probes the difference of activity between listening to some content or reading the same type of content (instructions, stories).\n",
    "#\n",
    "# Of course, we could define other contrasts, but we keep only this one for simplicity.\n",
    "\n",
    "\n",
    "contrast_id = \"left - right button press\"\n",
    "contrast_val = (\n",
    "    basic_contrasts[\"audio_left_hand_button_press\"]\n",
    "    - basic_contrasts[\"audio_right_hand_button_press\"]\n",
    "    + basic_contrasts[\"visual_left_hand_button_press\"]\n",
    "    - basic_contrasts[\"visual_right_hand_button_press\"]\n",
    ")\n",
    "# contrast_id = \"audio-visual\"\n",
    "# contrast_val = basic_contrasts[\"audio\"] - basic_contrasts[\"visual\"]\n",
    "\n",
    "from nilearn.glm.contrasts import compute_contrast\n",
    "from nilearn import plotting\n",
    "\n",
    "# compute contrast-related statistics\n",
    "contrast = compute_contrast(labels, estimates, contrast_val, contrast_type=\"t\")\n",
    "# we present the associated z-score\n",
    "p_value = contrast.p_value()\n",
    "# we plot it on the surface, on the inflated fsaverage mesh,\n",
    "# together with a suitable background to give an impression\n",
    "# of the cortex folding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04096798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relevant contrast\n",
    "plotting.plot_surf_stat_map(\n",
    "    fsaverage.infl_right,\n",
    "    1 - p_value,\n",
    "    hemi=\"right\",\n",
    "    title=contrast_id,\n",
    "    colorbar=True,\n",
    "    threshold=None,\n",
    "    bg_map=fsaverage.sulc_right,\n",
    ")\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c3f0fb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_usual_threshold():\n",
    "    \"\"\"Q8.\n",
    "\n",
    "    Threshold the contrast \"left - right button press\"\n",
    "    so that only voxels\n",
    "    with p-value lower than 5% are displayed\n",
    "\n",
    "    Help: use the threshold argument of plot_surf_stat_map\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "plot_usual_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6333fbf",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_bonferroni_correction():\n",
    "    \"\"\"Q9.\n",
    "\n",
    "    Threshold the contrast \"left - right button press\"\n",
    "    according to Bonferroni correction.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "plot_bonferroni_correction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a926e2f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_benjamini_yekutieli():\n",
    "    \"\"\"Q10.\n",
    "\n",
    "    Threshold the contrast \"left - right button press\"\n",
    "    according to Benjamini Yekutieli procedure\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "plot_benjamini_yekutieli()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8efcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_benjamini_hochberg():\n",
    "    \"\"\"Q11.\n",
    "\n",
    "    Threshold the contrast \"left - right button press\"\n",
    "    according to Benjamini Hochberg procedure\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "plot_benjamini_hochberg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b335dbec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "auto:percent,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
